{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-ui6LGstotGIJY3Go7wPseq-FhhGlbVx",
      "authorship_tag": "ABX9TyNslWhrS+UmCfPP0CKF1wAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsjj10002/FackVoiceClassfication/blob/main/%EC%9D%8C%EC%84%B1_%ED%8C%90%EB%B3%84_%EB%AA%A8%EB%8D%B8_CNN%2B%EC%96%91%EB%B0%A9%ED%96%A5LSTM%2Bk_fold_%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용 데이터셋\n",
        "\n",
        "[The Fake-or-Real (FoR) Dataset](https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset/data)\n",
        "\n",
        "The Fake-or-Real (FoR) dataset is a collection of more than 195,000 utterances from real humans and computer generated speech. The dataset can be used to train classifiers to detect synthetic speech. The dataset is published in four versions: for-original, for-norm, for-2sec and for-rerec.\n",
        "\n",
        "The first version, named for-original, contains the files as collected from the speech sources, without any modification (balanced version).\n",
        "\n",
        "***The second version, called for-norm, contains the same files, but balanced in terms of gender and class and normalized in terms of sample rate, volume and number of channels.***\n",
        "\n",
        "The third one, named for-2sec is based on the second one, but with the files truncated at 2 seconds.\n",
        "\n",
        "The last version, named for-rerec, is a rerecorded version of the for-2second dataset, to simulate a scenario where an attacker sends an utterance through a voice channel (i.e. a phone call or a voice message).\n",
        "\n",
        "사용한 버전: 정규화 버젼"
      ],
      "metadata": {
        "id": "HnY-gW0c4QMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케글 API 불러온 후 데이터셋 다운로드\n"
      ],
      "metadata": {
        "id": "S5pqcCbC4wK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Mnp2CPxa6hDi7_hkwUrleP6pQqulrXz0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CSa-XRe8w_6",
        "outputId": "32636132-2172-4c09-e043-d4926cfecc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mnp2CPxa6hDi7_hkwUrleP6pQqulrXz0\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/67.0 [00:00<?, ?B/s]\r100% 67.0/67.0 [00:00<00:00, 233kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2RsIyTy4IiN",
        "outputId": "4a32cac9-940b-4a37-b5ad-92fb412a5c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset\n",
            "License(s): GNU Lesser General Public License 3.0\n",
            "Downloading the-fake-or-real-dataset.zip to /content\n",
            "100% 16.0G/16.0G [02:43<00:00, 197MB/s]\n",
            "100% 16.0G/16.0G [02:43<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mohammedabdeldayem/the-fake-or-real-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!mkdir the-fake-or-real-dataset\n",
        "!unzip -qq \"/content/the-fake-or-real-dataset.zip\" -d the-fake-or-real-dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWYH0v781U7",
        "outputId": "4a526f0c-9575-47a3-b102-07f17a750108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 음성파일 경로 수집"
      ],
      "metadata": {
        "id": "Aogyopzw9PK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 기본 경로 설정\n",
        "base_path = \"/content/the-fake-or-real-dataset/for-norm/for-norm\"\n",
        "\n",
        "# 카테고리와 타입 정의\n",
        "categories = ['testing', 'training', 'validation']\n",
        "types = ['fake', 'real']\n",
        "\n",
        "# 모든 파일 경로 수집\n",
        "data = []\n",
        "for category in categories:\n",
        "    for type_ in types:\n",
        "        dir_path = os.path.join(base_path, category, type_)\n",
        "        for filename in os.listdir(dir_path):\n",
        "            if filename.endswith('.wav'):\n",
        "                full_path = os.path.join(dir_path, filename)\n",
        "                data.append({'path': full_path, 'label': type_, 'category': category})\n",
        "\n",
        "# DataFrame 생성\n",
        "path_df = pd.DataFrame(data)\n",
        "print(\"Dataframe shape:\", path_df.shape)\n",
        "print(path_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Bm5Ze99Omr",
        "outputId": "b8ac7cf8-7d7f-4b12-853c-2a6856d52490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (69300, 3)\n",
            "                                                path label category\n",
            "0  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "1  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "2  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "3  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "4  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.MFCC 특징 추출"
      ],
      "metadata": {
        "id": "uyX6CYC99a3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_mfcc(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "        if audio.size == 0:\n",
        "            return None\n",
        "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        return mfcc_mean\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# MFCC 특징을 병렬로 추출\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_row(row):\n",
        "    mfcc = extract_mfcc(row['path'])\n",
        "    if mfcc is not None:\n",
        "        return {'path': row['path'], 'mfcc': mfcc, 'label': row['label'], 'category': row['category']}\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# 데이터프레임에서 병렬 처리를 위해 데이터를 리스트로 변환\n",
        "data_list = path_df.to_dict('records')\n",
        "# 병렬 처리 설정\n",
        "with Pool(processes=4) as pool:\n",
        "    results = pool.map(process_row, data_list)\n",
        "\n",
        "# None을 제거하고 데이터프레임 생성\n",
        "mfcc_data = [result for result in results if result is not None]\n",
        "mfcc_df = pd.DataFrame(mfcc_data)\n",
        "\n",
        "print(\"MFCC DataFrame shape:\", mfcc_df.shape)\n",
        "print(mfcc_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNTt1bXY9W78",
        "outputId": "20ebdb44-fd3e-4d3c-b6d4-2057e83e316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1891\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1837\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1690\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCC DataFrame shape: (69298, 4)\n",
            "                                                path  \\\n",
            "0  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "1  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "2  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "3  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "4  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "\n",
            "                                                mfcc label category  \n",
            "0  [-121.118385, 104.168976, -17.292633, 7.035876...  fake  testing  \n",
            "1  [-133.96411, 77.051575, -3.4393408, 11.727731,...  fake  testing  \n",
            "2  [-153.86955, 123.38464, -12.190086, 23.369476,...  fake  testing  \n",
            "3  [-126.404106, 96.755585, -7.130523, 5.172734, ...  fake  testing  \n",
            "4  [-136.06691, 120.67819, -12.658545, 18.204365,...  fake  testing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.데이터셋 분할"
      ],
      "metadata": {
        "id": "7qjQrftv9h_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = mfcc_df[mfcc_df['category'] == 'training']\n",
        "val_df = mfcc_df[mfcc_df['category'] == 'validation']\n",
        "test_df = mfcc_df[mfcc_df['category'] == 'testing']\n",
        "\n",
        "print(\"Training Data Shape:\", train_df.shape)\n",
        "print(\"Validation Data Shape:\", val_df.shape)\n",
        "print(\"Testing Data Shape:\", test_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7nB2LDP9iVa",
        "outputId": "7cec2932-baed-4bed-e8e0-5bfa550e0b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape: (53866, 4)\n",
            "Validation Data Shape: (10798, 4)\n",
            "Testing Data Shape: (4634, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4,데이터 준비"
      ],
      "metadata": {
        "id": "P_-lMbpX9wAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.vstack(train_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_train = train_df['label'].values\n",
        "\n",
        "X_val = np.vstack(val_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_val = val_df['label'].values\n",
        "\n",
        "X_test = np.vstack(test_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_test = test_df['label'].values\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"Y_val shape:\", Y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"Y_test shape:\", Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s16OH-GX9z2q",
        "outputId": "77689a95-fe2c-4a39-a421-279a71cbcfec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (53866, 13)\n",
            "Y_train shape: (53866,)\n",
            "X_val shape: (10798, 13)\n",
            "Y_val shape: (10798,)\n",
            "X_test shape: (4634, 13)\n",
            "Y_test shape: (4634,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 라이브러리"
      ],
      "metadata": {
        "id": "SchKxSAmNDrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "60NlcDuwNCTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.데이터 정규화"
      ],
      "metadata": {
        "id": "bfnbMTntMiAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# StandardScaler를 사용하여 특징 데이터의 스케일을 조정합니다.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "rbqvNPYUMniI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.레이블 인코딩"
      ],
      "metadata": {
        "id": "R0wUl3vSNSmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 레이블을 숫자로 변환.\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train)\n",
        "Y_val = encoder.transform(Y_val)\n",
        "Y_test = encoder.transform(Y_test)"
      ],
      "metadata": {
        "id": "8xqz77ClNV_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-1 원-핫 인코딩"
      ],
      "metadata": {
        "id": "M2DdN0puNmfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 작업을 위해 레이블을 원-핫 인코딩 형식으로 변환.\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_val = to_categorical(Y_val)\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "aslVGvh2NuCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.모델 구축"
      ],
      "metadata": {
        "id": "o30kJNUuLcJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 신경망 모델을 구성. 입력 레이어, 두 개의 숨겨진 레이어, 그리고 출력 레이어로 구성.\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),  # 입력 레이어\n",
        "    Dense(128, activation='relu'),                                   # 은닉층\n",
        "    Dense(Y_train.shape[1], activation='softmax')                    # 출력 레이어, 클래스 수만큼 출력 노드를 가짐\n",
        "])\n",
        "# 모델 컴파일. 손실 함수로는 'categorical_crossentropy'를 사용하며, 최적화기로는 'adam'을 사용.\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "coyzTzc2Ksn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.모델 훈련"
      ],
      "metadata": {
        "id": "b0gzBPRxMGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "# 모델을 훈련 데이터로 훈련하고, 검증 데이터로 각 에포크마다 성능을 평가합니다.\n",
        "model.fit(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9EvGfRIL5Ut",
        "outputId": "bd24537e-eadc-4404-a4a5-19ab15ed56ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1684/1684 [==============================] - 8s 4ms/step - loss: 0.1617 - accuracy: 0.9398 - val_loss: 0.0961 - val_accuracy: 0.9674\n",
            "Epoch 2/10\n",
            "1684/1684 [==============================] - 9s 5ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.0742 - val_accuracy: 0.9748\n",
            "Epoch 3/10\n",
            "1684/1684 [==============================] - 6s 4ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.0641 - val_accuracy: 0.9766\n",
            "Epoch 4/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0771 - val_accuracy: 0.9716\n",
            "Epoch 5/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0535 - val_accuracy: 0.9806\n",
            "Epoch 6/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 0.0578 - val_accuracy: 0.9795\n",
            "Epoch 7/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.0603 - val_accuracy: 0.9804\n",
            "Epoch 8/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.0493 - val_accuracy: 0.9819\n",
            "Epoch 9/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.0465 - val_accuracy: 0.9836\n",
            "Epoch 10/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.0621 - val_accuracy: 0.9794\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79abc9ca2980>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.모델평가"
      ],
      "metadata": {
        "id": "c1KznXFFO4_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 모델을 테스트 데이터로 평가.\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-jD8co9O9Xy",
        "outputId": "b7fd6dba-62ef-49c8-c07f-5865bac83c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145/145 [==============================] - 0s 2ms/step - loss: 1.9276 - accuracy: 0.5050\n",
            "Test Accuracy: 50.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. CNN + LSTM"
      ],
      "metadata": {
        "id": "QQ47NT_zSY99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, LSTM, Flatten\n",
        "\n",
        "# 모델 구성\n",
        "model = Sequential([\n",
        "    # 첫 번째 합성곱 레이어\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # 두 번째 합성곱 레이어\n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # LSTM 레이어\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # 완전 연결 레이어\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # 출력 레이어\n",
        "    Dense(Y_train.shape[1], activation='softmax')\n",
        "])\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J9azz2eSYpI",
        "outputId": "e7ee512d-fa56-49d5-fcb7-0dcc0b0cc997"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 11, 64)            256       \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 5, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 5, 64)             0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 3, 128)            24704     \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPoolin  (None, 1, 128)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1, 128)            131584    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 1, 128)            0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173314 (677.01 KB)\n",
            "Trainable params: 173314 (677.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-1 모델훈련"
      ],
      "metadata": {
        "id": "P8BCWAWtS9_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=20, validation_data=(X_val, Y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzPb6nYKTTqy",
        "outputId": "fe25e7b4-927d-478e-c5c6-2f3606d4c374"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1684/1684 [==============================] - 21s 10ms/step - loss: 0.3818 - accuracy: 0.8272 - val_loss: 0.2466 - val_accuracy: 0.8982\n",
            "Epoch 2/20\n",
            "1684/1684 [==============================] - 16s 9ms/step - loss: 0.2768 - accuracy: 0.8835 - val_loss: 0.2172 - val_accuracy: 0.9129\n",
            "Epoch 3/20\n",
            "1684/1684 [==============================] - 16s 9ms/step - loss: 0.2484 - accuracy: 0.8967 - val_loss: 0.2009 - val_accuracy: 0.9184\n",
            "Epoch 4/20\n",
            "1684/1684 [==============================] - 15s 9ms/step - loss: 0.2308 - accuracy: 0.9050 - val_loss: 0.1812 - val_accuracy: 0.9261\n",
            "Epoch 5/20\n",
            "1684/1684 [==============================] - 16s 9ms/step - loss: 0.2193 - accuracy: 0.9106 - val_loss: 0.1789 - val_accuracy: 0.9263\n",
            "Epoch 6/20\n",
            "1684/1684 [==============================] - 17s 10ms/step - loss: 0.2131 - accuracy: 0.9130 - val_loss: 0.1626 - val_accuracy: 0.9347\n",
            "Epoch 7/20\n",
            "1684/1684 [==============================] - 17s 10ms/step - loss: 0.2026 - accuracy: 0.9170 - val_loss: 0.1596 - val_accuracy: 0.9352\n",
            "Epoch 8/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1961 - accuracy: 0.9217 - val_loss: 0.1589 - val_accuracy: 0.9347\n",
            "Epoch 9/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1909 - accuracy: 0.9229 - val_loss: 0.1458 - val_accuracy: 0.9423\n",
            "Epoch 10/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1823 - accuracy: 0.9261 - val_loss: 0.1395 - val_accuracy: 0.9429\n",
            "Epoch 11/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1819 - accuracy: 0.9279 - val_loss: 0.1369 - val_accuracy: 0.9465\n",
            "Epoch 12/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1768 - accuracy: 0.9300 - val_loss: 0.1364 - val_accuracy: 0.9463\n",
            "Epoch 13/20\n",
            "1684/1684 [==============================] - 18s 11ms/step - loss: 0.1741 - accuracy: 0.9311 - val_loss: 0.1295 - val_accuracy: 0.9497\n",
            "Epoch 14/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1699 - accuracy: 0.9316 - val_loss: 0.1295 - val_accuracy: 0.9491\n",
            "Epoch 15/20\n",
            "1684/1684 [==============================] - 18s 11ms/step - loss: 0.1651 - accuracy: 0.9338 - val_loss: 0.1272 - val_accuracy: 0.9486\n",
            "Epoch 16/20\n",
            "1684/1684 [==============================] - 16s 10ms/step - loss: 0.1626 - accuracy: 0.9364 - val_loss: 0.1250 - val_accuracy: 0.9513\n",
            "Epoch 17/20\n",
            "1684/1684 [==============================] - 18s 10ms/step - loss: 0.1600 - accuracy: 0.9378 - val_loss: 0.1261 - val_accuracy: 0.9518\n",
            "Epoch 18/20\n",
            "1684/1684 [==============================] - 18s 11ms/step - loss: 0.1600 - accuracy: 0.9369 - val_loss: 0.1256 - val_accuracy: 0.9521\n",
            "Epoch 19/20\n",
            "1684/1684 [==============================] - 18s 10ms/step - loss: 0.1568 - accuracy: 0.9373 - val_loss: 0.1204 - val_accuracy: 0.9543\n",
            "Epoch 20/20\n",
            "1684/1684 [==============================] - 17s 10ms/step - loss: 0.1567 - accuracy: 0.9384 - val_loss: 0.1217 - val_accuracy: 0.9537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79abc5e25390>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-2.모델평가"
      ],
      "metadata": {
        "id": "1gl4ZSx9U6RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYRjp8KbU5jo",
        "outputId": "4eed4c88-ff00-455e-df2c-23f8c28fd3d2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145/145 [==============================] - 1s 5ms/step - loss: 0.9543 - accuracy: 0.5863\n",
            "Test Accuracy: 58.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. CNN, 양방향 LSTM, L1,L2정규화,k-fold교차검증을 적용"
      ],
      "metadata": {
        "id": "05zs4eTwbUEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D, Bidirectional, LSTM, Flatten\n",
        "from tensorflow.keras.regularizers import l1_l2"
      ],
      "metadata": {
        "id": "8ZzX-JNYbwo5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11-1. 모델 구축"
      ],
      "metadata": {
        "id": "VTYl_r0mcG3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_advanced_model(input_shape, output_units):\n",
        "    model = Sequential([\n",
        "        # 첫 번째 합성곱 레이어와 풀링\n",
        "        Conv1D(64, kernel_size=5, activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # 두 번째 합성곱 레이어와 풀링\n",
        "        Conv1D(128, kernel_size=5, activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # 세 번째 합성곱 레이어와 풀링\n",
        "        Conv1D(256, kernel_size=5, activation='relu', padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # 양방향 LSTM 레이어\n",
        "        Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # 데이터 평탄화\n",
        "        Flatten(),\n",
        "\n",
        "        # 완전 연결 레이어\n",
        "        Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # 출력 레이어\n",
        "        Dense(output_units, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 컴파일\n",
        "    model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hh0dccBhcGg4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11-2 k-fold 교차검즘 실행"
      ],
      "metadata": {
        "id": "q1GNwJ0-cch_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X와 Y 데이터 병합\n",
        "X = np.concatenate([X_train, X_val, X_test], axis=0)\n",
        "Y = np.concatenate([Y_train, Y_val, Y_test], axis=0)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Y shape:\", Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLQVEXo2e_Et",
        "outputId": "89880281-f28a-41a7-b3dd-fd136d416113"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (69298, 13)\n",
            "Y shape: (69298, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# k-Fold 교차 검증 설정\n",
        "n_splits = 5\n",
        "input_shape = (X.shape[1], 1) # 입력 차원 설정\n",
        "output_units = np.unique(Y).shape[0] # 출력 유닛 수는 유니크한 레이블 수\n",
        "\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "\n",
        "accuracies = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    # 모델 생성 및 훈련\n",
        "    model = build_advanced_model(input_shape, output_units)\n",
        "    print(f'Training fold {fold_no}...')\n",
        "    model.fit(X_train, Y_train, batch_size=16, epochs=20, validation_data=(X_test, Y_test))\n",
        "\n",
        "    # 평가\n",
        "    _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f'Score for fold {fold_no}: Accuracy of {accuracy*100:.2f}%')\n",
        "    fold_no += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "hQP0eecqcieQ",
        "outputId": "fcc027cc-ec68-41d8-a1a5-7a48d1b6d388"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 1...\n",
            "Epoch 1/20\n",
            "2455/3465 [====================>.........] - ETA: 24s - loss: 0.4542 - accuracy: 0.8284"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-660b9ad3bc5a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_advanced_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training fold {fold_no}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 평가: 평균 정확도 및 표준 편차 계산\n",
        "average_accuracy = np.mean(accuracies)\n",
        "std_deviation = np.std(accuracies)\n",
        "print(f'Final Mean Accuracy: {average_accuracy*100:.2f}%')\n",
        "print(f'Standard Deviation of Accuracies: {std_deviation*100:.2f}%')\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kf_qc4UC1294"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}