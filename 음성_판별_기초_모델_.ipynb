{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1-ui6LGstotGIJY3Go7wPseq-FhhGlbVx",
      "authorship_tag": "ABX9TyNXgpIJETPv/Qo4A257vJ0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsjj10002/FackVoiceClassfication/blob/main/%EC%9D%8C%EC%84%B1_%ED%8C%90%EB%B3%84_%EA%B8%B0%EC%B4%88_%EB%AA%A8%EB%8D%B8_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용 데이터셋\n",
        "\n",
        "[The Fake-or-Real (FoR) Dataset](https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset/data)\n",
        "\n",
        "The Fake-or-Real (FoR) dataset is a collection of more than 195,000 utterances from real humans and computer generated speech. The dataset can be used to train classifiers to detect synthetic speech. The dataset is published in four versions: for-original, for-norm, for-2sec and for-rerec.\n",
        "\n",
        "The first version, named for-original, contains the files as collected from the speech sources, without any modification (balanced version).\n",
        "\n",
        "***The second version, called for-norm, contains the same files, but balanced in terms of gender and class and normalized in terms of sample rate, volume and number of channels.***\n",
        "\n",
        "The third one, named for-2sec is based on the second one, but with the files truncated at 2 seconds.\n",
        "\n",
        "The last version, named for-rerec, is a rerecorded version of the for-2second dataset, to simulate a scenario where an attacker sends an utterance through a voice channel (i.e. a phone call or a voice message).\n",
        "\n",
        "사용한 버전: 정규화 버젼"
      ],
      "metadata": {
        "id": "HnY-gW0c4QMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케글 API 불러온 후 데이터셋 다운로드\n"
      ],
      "metadata": {
        "id": "S5pqcCbC4wK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Mnp2CPxa6hDi7_hkwUrleP6pQqulrXz0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CSa-XRe8w_6",
        "outputId": "32636132-2172-4c09-e043-d4926cfecc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mnp2CPxa6hDi7_hkwUrleP6pQqulrXz0\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/67.0 [00:00<?, ?B/s]\r100% 67.0/67.0 [00:00<00:00, 233kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2RsIyTy4IiN",
        "outputId": "4a32cac9-940b-4a37-b5ad-92fb412a5c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset\n",
            "License(s): GNU Lesser General Public License 3.0\n",
            "Downloading the-fake-or-real-dataset.zip to /content\n",
            "100% 16.0G/16.0G [02:43<00:00, 197MB/s]\n",
            "100% 16.0G/16.0G [02:43<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mohammedabdeldayem/the-fake-or-real-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!mkdir the-fake-or-real-dataset\n",
        "!unzip -qq \"/content/the-fake-or-real-dataset.zip\" -d the-fake-or-real-dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWYH0v781U7",
        "outputId": "4a526f0c-9575-47a3-b102-07f17a750108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 음성파일 경로 수집"
      ],
      "metadata": {
        "id": "Aogyopzw9PK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 기본 경로 설정\n",
        "base_path = \"/content/the-fake-or-real-dataset/for-norm/for-norm\"\n",
        "\n",
        "# 카테고리와 타입 정의\n",
        "categories = ['testing', 'training', 'validation']\n",
        "types = ['fake', 'real']\n",
        "\n",
        "# 모든 파일 경로 수집\n",
        "data = []\n",
        "for category in categories:\n",
        "    for type_ in types:\n",
        "        dir_path = os.path.join(base_path, category, type_)\n",
        "        for filename in os.listdir(dir_path):\n",
        "            if filename.endswith('.wav'):\n",
        "                full_path = os.path.join(dir_path, filename)\n",
        "                data.append({'path': full_path, 'label': type_, 'category': category})\n",
        "\n",
        "# DataFrame 생성\n",
        "path_df = pd.DataFrame(data)\n",
        "print(\"Dataframe shape:\", path_df.shape)\n",
        "print(path_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Bm5Ze99Omr",
        "outputId": "b8ac7cf8-7d7f-4b12-853c-2a6856d52490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (69300, 3)\n",
            "                                                path label category\n",
            "0  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "1  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "2  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "3  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n",
            "4  /content/the-fake-or-real-dataset/for-norm/for...  fake  testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.MFCC 특징 추출"
      ],
      "metadata": {
        "id": "uyX6CYC99a3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_mfcc(file_path):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "        if audio.size == 0:\n",
        "            return None\n",
        "        mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        return mfcc_mean\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# MFCC 특징을 병렬로 추출\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_row(row):\n",
        "    mfcc = extract_mfcc(row['path'])\n",
        "    if mfcc is not None:\n",
        "        return {'path': row['path'], 'mfcc': mfcc, 'label': row['label'], 'category': row['category']}\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# 데이터프레임에서 병렬 처리를 위해 데이터를 리스트로 변환\n",
        "data_list = path_df.to_dict('records')\n",
        "# 병렬 처리 설정\n",
        "with Pool(processes=4) as pool:\n",
        "    results = pool.map(process_row, data_list)\n",
        "\n",
        "# None을 제거하고 데이터프레임 생성\n",
        "mfcc_data = [result for result in results if result is not None]\n",
        "mfcc_df = pd.DataFrame(mfcc_data)\n",
        "\n",
        "print(\"MFCC DataFrame shape:\", mfcc_df.shape)\n",
        "print(mfcc_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNTt1bXY9W78",
        "outputId": "20ebdb44-fd3e-4d3c-b6d4-2057e83e316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1891\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1837\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1690\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCC DataFrame shape: (69298, 4)\n",
            "                                                path  \\\n",
            "0  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "1  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "2  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "3  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "4  /content/the-fake-or-real-dataset/for-norm/for...   \n",
            "\n",
            "                                                mfcc label category  \n",
            "0  [-121.118385, 104.168976, -17.292633, 7.035876...  fake  testing  \n",
            "1  [-133.96411, 77.051575, -3.4393408, 11.727731,...  fake  testing  \n",
            "2  [-153.86955, 123.38464, -12.190086, 23.369476,...  fake  testing  \n",
            "3  [-126.404106, 96.755585, -7.130523, 5.172734, ...  fake  testing  \n",
            "4  [-136.06691, 120.67819, -12.658545, 18.204365,...  fake  testing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.데이터셋 분할"
      ],
      "metadata": {
        "id": "7qjQrftv9h_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = mfcc_df[mfcc_df['category'] == 'training']\n",
        "val_df = mfcc_df[mfcc_df['category'] == 'validation']\n",
        "test_df = mfcc_df[mfcc_df['category'] == 'testing']\n",
        "\n",
        "print(\"Training Data Shape:\", train_df.shape)\n",
        "print(\"Validation Data Shape:\", val_df.shape)\n",
        "print(\"Testing Data Shape:\", test_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7nB2LDP9iVa",
        "outputId": "7cec2932-baed-4bed-e8e0-5bfa550e0b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape: (53866, 4)\n",
            "Validation Data Shape: (10798, 4)\n",
            "Testing Data Shape: (4634, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4,데이터 준비"
      ],
      "metadata": {
        "id": "P_-lMbpX9wAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.vstack(train_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_train = train_df['label'].values\n",
        "\n",
        "X_val = np.vstack(val_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_val = val_df['label'].values\n",
        "\n",
        "X_test = np.vstack(test_df['mfcc'].apply(lambda x: np.array(x)).values)\n",
        "Y_test = test_df['label'].values\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"Y_val shape:\", Y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"Y_test shape:\", Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s16OH-GX9z2q",
        "outputId": "77689a95-fe2c-4a39-a421-279a71cbcfec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (53866, 13)\n",
            "Y_train shape: (53866,)\n",
            "X_val shape: (10798, 13)\n",
            "Y_val shape: (10798,)\n",
            "X_test shape: (4634, 13)\n",
            "Y_test shape: (4634,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 라이브러리"
      ],
      "metadata": {
        "id": "SchKxSAmNDrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "60NlcDuwNCTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.데이터 정규화"
      ],
      "metadata": {
        "id": "bfnbMTntMiAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# StandardScaler를 사용하여 특징 데이터의 스케일을 조정합니다.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "rbqvNPYUMniI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.레이블 인코딩"
      ],
      "metadata": {
        "id": "R0wUl3vSNSmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 레이블을 숫자로 변환.\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train)\n",
        "Y_val = encoder.transform(Y_val)\n",
        "Y_test = encoder.transform(Y_test)"
      ],
      "metadata": {
        "id": "8xqz77ClNV_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-1 원-핫 인코딩"
      ],
      "metadata": {
        "id": "M2DdN0puNmfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 작업을 위해 레이블을 원-핫 인코딩 형식으로 변환.\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_val = to_categorical(Y_val)\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "aslVGvh2NuCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.모델 구축"
      ],
      "metadata": {
        "id": "o30kJNUuLcJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 신경망 모델을 구성. 입력 레이어, 두 개의 숨겨진 레이어, 그리고 출력 레이어로 구성.\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),  # 입력 레이어\n",
        "    Dense(128, activation='relu'),                                   # 은닉층\n",
        "    Dense(Y_train.shape[1], activation='softmax')                    # 출력 레이어, 클래스 수만큼 출력 노드를 가짐\n",
        "])\n",
        "# 모델 컴파일. 손실 함수로는 'categorical_crossentropy'를 사용하며, 최적화기로는 'adam'을 사용.\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "coyzTzc2Ksn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.모델 훈련"
      ],
      "metadata": {
        "id": "b0gzBPRxMGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "# 모델을 훈련 데이터로 훈련하고, 검증 데이터로 각 에포크마다 성능을 평가합니다.\n",
        "model.fit(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9EvGfRIL5Ut",
        "outputId": "bd24537e-eadc-4404-a4a5-19ab15ed56ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1684/1684 [==============================] - 8s 4ms/step - loss: 0.1617 - accuracy: 0.9398 - val_loss: 0.0961 - val_accuracy: 0.9674\n",
            "Epoch 2/10\n",
            "1684/1684 [==============================] - 9s 5ms/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.0742 - val_accuracy: 0.9748\n",
            "Epoch 3/10\n",
            "1684/1684 [==============================] - 6s 4ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 0.0641 - val_accuracy: 0.9766\n",
            "Epoch 4/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0771 - val_accuracy: 0.9716\n",
            "Epoch 5/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.0535 - val_accuracy: 0.9806\n",
            "Epoch 6/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0426 - accuracy: 0.9850 - val_loss: 0.0578 - val_accuracy: 0.9795\n",
            "Epoch 7/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.0603 - val_accuracy: 0.9804\n",
            "Epoch 8/10\n",
            "1684/1684 [==============================] - 4s 2ms/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.0493 - val_accuracy: 0.9819\n",
            "Epoch 9/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.0465 - val_accuracy: 0.9836\n",
            "Epoch 10/10\n",
            "1684/1684 [==============================] - 5s 3ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.0621 - val_accuracy: 0.9794\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79abc9ca2980>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.모델평가"
      ],
      "metadata": {
        "id": "c1KznXFFO4_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 모델을 테스트 데이터로 평가.\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-jD8co9O9Xy",
        "outputId": "b7fd6dba-62ef-49c8-c07f-5865bac83c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145/145 [==============================] - 0s 2ms/step - loss: 1.9276 - accuracy: 0.5050\n",
            "Test Accuracy: 50.50%\n"
          ]
        }
      ]
    }
  ]
}